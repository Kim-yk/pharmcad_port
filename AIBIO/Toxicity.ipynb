{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled80.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_PilJoXaqK8",
        "outputId": "137bd833-de0b-4ec7-bc15-909463baf02a"
      },
      "source": [
        "! pip install deepchem  \n",
        "!wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv # 데이터 불러오기\n",
        "# ! pip install tensorflow~=2.4\n",
        "! pip install tensorflow==1.15\n",
        "!pip install kora\n",
        "! pip install MolVS\n",
        "! pip install keras==1.2.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.5.0-py3-none-any.whl (552 kB)\n",
            "\u001b[K     |████████████████████████████████| 552 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deepchem) (3.0.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.5.0\n",
            "--2021-12-04 13:25:59--  https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96699 (94K) [text/plain]\n",
            "Saving to: ‘delaney-processed.csv’\n",
            "\n",
            "delaney-processed.c 100%[===================>]  94.43K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-12-04 13:26:00 (6.66 MB/s) - ‘delaney-processed.csv’ saved [96699/96699]\n",
            "\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 27 kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.42.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.13.3)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=0d65de8094f7ea85258c120edda59fe079e41e4f44ceaaa6f982c1eca3e62763\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting kora\n",
            "  Downloading kora-0.9.19-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting fastcore\n",
            "  Downloading fastcore-1.3.27-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.3)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (3.0.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Installing collected packages: fastcore, kora\n",
            "Successfully installed fastcore-1.3.27 kora-0.9.19\n",
            "Collecting MolVS\n",
            "  Downloading MolVS-0.1.1.tar.gz (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 465 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from MolVS) (1.15.0)\n",
            "Building wheels for collected packages: MolVS\n",
            "  Building wheel for MolVS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MolVS: filename=MolVS-0.1.1-py3-none-any.whl size=32386 sha256=35980dd8b652757e533500c676034958753a07372e8805036f96cc6c9d91d18e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/c2/92/e85190307603c2b3733d43e357abae2d1c66b609bfbba6200d\n",
            "Successfully built MolVS\n",
            "Installing collected packages: MolVS\n",
            "Successfully installed MolVS-0.1.1\n",
            "Collecting keras==1.2.2\n",
            "  Downloading Keras-1.2.2.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting theano\n",
            "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==1.2.2) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras==1.2.2) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.2.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.2.2) (1.4.1)\n",
            "Building wheels for collected packages: keras, theano\n",
            "  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras: filename=Keras-1.2.2-py3-none-any.whl size=209599 sha256=32cf8236503b56bcb719f3762f5e0e932ea8211af3f24c5017a113cdd821ccb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/32/23/2a1db3765ec19c91503843380a4f92b6530598949c661c5fa2\n",
            "  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano: filename=Theano-1.0.5-py3-none-any.whl size=2668111 sha256=39b1425f2f8c0c14c44700579affe126ea6c14a412ff7cea6a1aed53e264b01c\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/68/6f/745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n",
            "Successfully built keras theano\n",
            "Installing collected packages: theano, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "Successfully installed keras-1.2.2 theano-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFwz9KRgILN4",
        "outputId": "60160cf2-d582-4030-c98a-112f1e37f5c1"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pdcoded/fox/master/tox21_sdf/tox21_10k_data_all.sdf -O"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 23.5M  100 23.5M    0     0  47.4M      0 --:--:-- --:--:-- --:--:-- 47.4M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0QyyanrawAT"
      },
      "source": [
        "import kora.install.rdkit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWL73c2_2CPw"
      },
      "source": [
        "Toxicity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9as1o8U7ZCH",
        "outputId": "cf9e4479-1e7c-4432-cad9-0b932eba00d2"
      },
      "source": [
        "#Pandas and Numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#RDkit for fingerprinting and cheminformatics\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem, rdMolDescriptors\n",
        "#MolVS for standardization and normalization of molecules\n",
        "import molvs as mv\n",
        "#Keras for deep learning\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from keras.regularizers import WeightRegularizer\n",
        "from keras.optimizers import SGD # from keras.optimizers import SGD --> from keras.optimizers import gradient_descent_v2 \n",
        "#SKlearn for metrics and datasplits\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "#Matplotlib for plotting\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "QH0WFysTCk20",
        "outputId": "75dd45c8-30da-4ec9-8fae-65457f624837"
      },
      "source": [
        "\"\"\"\n",
        "from rdkit import Chem\n",
        "import pandas as pd\n",
        "filename = \"tox21_10k_data_all.sdf\"\n",
        "basename = filename.split(\".\")[0]\n",
        "collector = []\n",
        "sdprovider = Chem.SDMolSupplier(filename)\n",
        "for i,mol in enumerate(sdprovider):\n",
        "    try:\n",
        "        moldict = {}\n",
        "        moldict['smiles'] = Chem.MolToSmiles(mol)\n",
        "        #Parse Data\n",
        "        for propname in mol.GetPropNames():\n",
        "            moldict[propname] = mol.GetProp(propname)\n",
        "        collector.append(moldict)\n",
        "    except:\n",
        "        print(\"Molecule %s failed\"%i)\n",
        "data = pd.DataFrame(collector)\n",
        "data.to_csv(basename + '_pandas.csv')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom rdkit import Chem\\nimport pandas as pd\\nfilename = \"tox21_10k_data_all.sdf\"\\nbasename = filename.split(\".\")[0]\\ncollector = []\\nsdprovider = Chem.SDMolSupplier(filename)\\nfor i,mol in enumerate(sdprovider):\\n    try:\\n        moldict = {}\\n        moldict[\\'smiles\\'] = Chem.MolToSmiles(mol)\\n        #Parse Data\\n        for propname in mol.GetPropNames():\\n            moldict[propname] = mol.GetProp(propname)\\n        collector.append(moldict)\\n    except:\\n        print(\"Molecule %s failed\"%i)\\ndata = pd.DataFrame(collector)\\ndata.to_csv(basename + \\'_pandas.csv\\')\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDj_zKafMVdp"
      },
      "source": [
        "def sdf_to_df(filepass):\n",
        "    mols = [mol for mol in Chem.SDMolSupplier(filepass) if mol is not None]\n",
        "    for id, mol in enumerate(mols):\n",
        "        if id == 0:\n",
        "            dicts = mol.GetPropsAsDict()\n",
        "            df = pd.DataFrame(dicts, index=[id,])\n",
        "        else:\n",
        "            dicts = mol.GetPropsAsDict()\n",
        "            dfplus = pd.DataFrame(dicts, index=[id,])\n",
        "            df = df.append(dfplus)\n",
        "    return mols, df\n",
        "\n",
        "train_x, train_df = sdf_to_df('./tox21_10k_data_all.sdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcoYA1-1Mzbw",
        "outputId": "a1dc8ba4-c537-4222-ed32-6ffd80362f6f"
      },
      "source": [
        "train_x[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7f9b5babfb20>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl-j3sdAM6Ye",
        "outputId": "2f9ef205-633d-4698-f210-20e7904f009a"
      },
      "source": [
        "mol1 = train_x[1]\n",
        "#print(Chem.MolToMolBlock(mol1))\n",
        "print(Chem.MolToSmiles(mol1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O=C([O-])c1ccccc1-c1c2cc(Br)c(=O)c(Br)c-2oc2c(Br)c([O-])c(Br)cc12.[Na+].[Na+]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "1-tBBpC_M7yy",
        "outputId": "0db01092-66de-4ef3-fbb2-a29a852bc55f"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from rdkit.Chem.Draw import rdMolDraw2D\n",
        "# SVG(Chem.MolToSVG(mol1))\n",
        "drawer = rdMolDraw2D.MolDraw2DSVG(300,300)\n",
        "drawer.DrawMolecule(mol1)\n",
        "drawer.FinishDrawing()\n",
        "svg = drawer.GetDrawingText()\n",
        "SVG(svg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"300px\" version=\"1.1\" viewBox=\"0 0 300 300\" width=\"300px\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<!-- END OF HEADER -->\n<rect height=\"300\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"300\" x=\"0\" y=\"0\"> </rect>\n<path class=\"bond-0\" d=\"M 191.195,104.199 L 191.195,132.746\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-1\" d=\"M 191.195,104.199 L 182.609,99.2209\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-1\" d=\"M 182.609,99.2209 L 174.024,94.2425\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-2\" d=\"M 191.195,104.199 L 215.803,89.9312\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-2\" d=\"M 197.999,107.428 L 215.225,97.4408\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-3\" d=\"M 191.195,132.746 L 166.589,146.773\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-3\" d=\"M 184.43,129.458 L 167.206,139.277\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-4\" d=\"M 191.195,132.746 L 215.803,146.773\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-5\" d=\"M 166.589,146.773 L 166.589,189.094\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-6\" d=\"M 166.589,146.773 L 141.984,132.746\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-7\" d=\"M 166.589,189.094 L 191.195,203.369\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-7\" d=\"M 167.165,196.604 L 184.389,206.596\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-8\" d=\"M 166.589,189.094 L 141.984,203.369\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-9\" d=\"M 191.195,203.369 L 215.803,189.094\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-10\" d=\"M 191.195,203.369 L 191.195,231.667\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-11\" d=\"M 215.803,189.094 L 224.389,194.075\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-11\" d=\"M 224.389,194.075 L 232.974,199.056\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-12\" d=\"M 218.907,189.094 L 218.907,178.996\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-12\" d=\"M 218.907,178.996 L 218.907,168.899\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-12\" d=\"M 212.7,189.094 L 212.7,178.996\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-12\" d=\"M 212.7,178.996 L 212.7,168.899\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-13\" d=\"M 191.195,231.667 L 166.589,245.939\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-13\" d=\"M 184.39,228.439 L 167.166,238.429\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-14\" d=\"M 166.589,245.939 L 141.984,231.667\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-15\" d=\"M 141.984,231.667 L 141.984,203.369\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-15\" d=\"M 148.19,227.423 L 148.19,207.614\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-16\" d=\"M 141.984,132.746 L 141.984,104.199\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-16\" d=\"M 135.777,128.464 L 135.777,108.481\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-17\" d=\"M 141.984,132.746 L 117.127,146.773\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-18\" d=\"M 141.984,104.199 L 150.569,99.2209\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-18\" d=\"M 150.569,99.2209 L 159.154,94.2425\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-19\" d=\"M 141.984,104.199 L 117.127,89.9312\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-20\" d=\"M 117.127,89.9312 L 92.5212,104.199\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-20\" d=\"M 116.549,97.4406 L 99.3255,107.428\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-21\" d=\"M 117.127,89.9312 L 117.127,79.6766\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-21\" d=\"M 117.127,79.6766 L 117.127,69.4221\" style=\"fill:none;fill-rule:evenodd;stroke:#7F4C19;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-22\" d=\"M 92.5212,104.199 L 92.5212,132.746\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-23\" d=\"M 92.5212,104.199 L 84.0557,99.241\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-23\" d=\"M 84.0557,99.241 L 75.5901,94.2827\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-24\" d=\"M 92.5212,132.746 L 117.127,146.773\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-24\" d=\"M 99.2858,129.458 L 116.51,139.277\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-25\" d=\"M 92.5212,132.746 L 82.2181,138.678\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-25\" d=\"M 82.2181,138.678 L 71.9149,144.611\" style=\"fill:none;fill-rule:evenodd;stroke:#7F4C19;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-26\" d=\"M 215.803,146.773 L 240.657,132.746\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-26\" d=\"M 216.481,139.263 L 233.878,129.445\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-27\" d=\"M 240.657,132.746 L 240.657,104.199\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-28\" d=\"M 240.657,132.746 L 250.12,138.139\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-28\" d=\"M 250.12,138.139 L 259.582,143.533\" style=\"fill:none;fill-rule:evenodd;stroke:#7F4C19;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-29\" d=\"M 240.657,104.199 L 215.803,89.9312\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-30\" d=\"M 242.214,106.884 L 250.801,101.905\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-30\" d=\"M 250.801,101.905 L 259.388,96.9266\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-30\" d=\"M 239.1,101.515 L 247.687,96.536\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-30\" d=\"M 247.687,96.536 L 256.274,91.5573\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-31\" d=\"M 215.803,89.9312 L 215.803,79.6766\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"bond-31\" d=\"M 215.803,79.6766 L 215.803,69.4221\" style=\"fill:none;fill-rule:evenodd;stroke:#7F4C19;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n<path class=\"atom-6\" d=\"M 233.685 203.411 Q 233.685 199.894, 235.423 197.928 Q 237.161 195.963, 240.409 195.963 Q 243.657 195.963, 245.395 197.928 Q 247.133 199.894, 247.133 203.411 Q 247.133 206.969, 245.374 208.996 Q 243.615 211.003, 240.409 211.003 Q 237.181 211.003, 235.423 208.996 Q 233.685 206.99, 233.685 203.411 M 240.409 209.348 Q 242.643 209.348, 243.843 207.859 Q 245.064 206.348, 245.064 203.411 Q 245.064 200.535, 243.843 199.087 Q 242.643 197.618, 240.409 197.618 Q 238.174 197.618, 236.954 199.066 Q 235.754 200.514, 235.754 203.411 Q 235.754 206.369, 236.954 207.859 Q 238.174 209.348, 240.409 209.348 \" fill=\"#FF0000\"/>\n<path class=\"atom-6\" d=\"M 247.815 198.353 L 252.826 198.353 L 252.826 199.446 L 247.815 199.446 L 247.815 198.353 \" fill=\"#FF0000\"/>\n<path class=\"atom-7\" d=\"M 209.08 160.592 Q 209.08 157.075, 210.817 155.11 Q 212.555 153.145, 215.803 153.145 Q 219.051 153.145, 220.789 155.11 Q 222.527 157.075, 222.527 160.592 Q 222.527 164.151, 220.769 166.178 Q 219.01 168.185, 215.803 168.185 Q 212.576 168.185, 210.817 166.178 Q 209.08 164.172, 209.08 160.592 M 215.803 166.53 Q 218.038 166.53, 219.238 165.04 Q 220.458 163.53, 220.458 160.592 Q 220.458 157.717, 219.238 156.269 Q 218.038 154.8, 215.803 154.8 Q 213.569 154.8, 212.348 156.248 Q 211.148 157.696, 211.148 160.592 Q 211.148 163.551, 212.348 165.04 Q 213.569 166.53, 215.803 166.53 \" fill=\"#FF0000\"/>\n<path class=\"atom-14\" d=\"M 159.865 89.9726 Q 159.865 86.4556, 161.603 84.4902 Q 163.341 82.5248, 166.589 82.5248 Q 169.837 82.5248, 171.575 84.4902 Q 173.313 86.4556, 173.313 89.9726 Q 173.313 93.531, 171.554 95.5585 Q 169.796 97.5653, 166.589 97.5653 Q 163.362 97.5653, 161.603 95.5585 Q 159.865 93.5517, 159.865 89.9726 M 166.589 95.9102 Q 168.823 95.9102, 170.023 94.4206 Q 171.244 92.9104, 171.244 89.9726 Q 171.244 87.0969, 170.023 85.6487 Q 168.823 84.1799, 166.589 84.1799 Q 164.355 84.1799, 163.134 85.6281 Q 161.934 87.0762, 161.934 89.9726 Q 161.934 92.9311, 163.134 94.4206 Q 164.355 95.9102, 166.589 95.9102 \" fill=\"#FF0000\"/>\n<path class=\"atom-19\" d=\"M 60.5163 146.4 Q 61.9231 146.793, 62.6265 147.662 Q 63.3506 148.51, 63.3506 149.772 Q 63.3506 151.8, 62.0472 152.958 Q 60.7645 154.096, 58.3233 154.096 L 53.3995 154.096 L 53.3995 139.449 L 57.7233 139.449 Q 60.2266 139.449, 61.4886 140.463 Q 62.7506 141.476, 62.7506 143.338 Q 62.7506 145.552, 60.5163 146.4 M 55.3649 141.104 L 55.3649 145.697 L 57.7233 145.697 Q 59.1715 145.697, 59.9163 145.118 Q 60.6818 144.518, 60.6818 143.338 Q 60.6818 141.104, 57.7233 141.104 L 55.3649 141.104 M 58.3233 152.441 Q 59.7508 152.441, 60.5163 151.759 Q 61.2817 151.076, 61.2817 149.772 Q 61.2817 148.573, 60.4335 147.973 Q 59.606 147.352, 58.013 147.352 L 55.3649 147.352 L 55.3649 152.441 L 58.3233 152.441 \" fill=\"#7F4C19\"/>\n<path class=\"atom-19\" d=\"M 66.6814 143.462 L 66.909 144.931 Q 68.0262 143.276, 69.8467 143.276 Q 70.426 143.276, 71.2122 143.483 L 70.9018 145.221 Q 70.0122 145.014, 69.5157 145.014 Q 68.6468 145.014, 68.0675 145.366 Q 67.5089 145.697, 67.0538 146.504 L 67.0538 154.096 L 65.1091 154.096 L 65.1091 143.462 L 66.6814 143.462 \" fill=\"#7F4C19\"/>\n<path class=\"atom-20\" d=\"M 61.4369 89.9726 Q 61.4369 86.4556, 63.1747 84.4902 Q 64.9126 82.5248, 68.1606 82.5248 Q 71.4087 82.5248, 73.1465 84.4902 Q 74.8844 86.4556, 74.8844 89.9726 Q 74.8844 93.531, 73.1258 95.5585 Q 71.3673 97.5653, 68.1606 97.5653 Q 64.9332 97.5653, 63.1747 95.5585 Q 61.4369 93.5517, 61.4369 89.9726 M 68.1606 95.9102 Q 70.395 95.9102, 71.5949 94.4206 Q 72.8155 92.9104, 72.8155 89.9726 Q 72.8155 87.0969, 71.5949 85.6487 Q 70.395 84.1799, 68.1606 84.1799 Q 65.9263 84.1799, 64.7057 85.6281 Q 63.5057 87.0762, 63.5057 89.9726 Q 63.5057 92.9311, 64.7057 94.4206 Q 65.9263 95.9102, 68.1606 95.9102 \" fill=\"#FF0000\"/>\n<path class=\"atom-20\" d=\"M 75.5671 84.9155 L 80.5782 84.9155 L 80.5782 86.0079 L 75.5671 86.0079 L 75.5671 84.9155 \" fill=\"#FF0000\"/>\n<path class=\"atom-21\" d=\"M 119.268 61.0123 Q 120.675 61.4054, 121.378 62.2743 Q 122.102 63.1225, 122.102 64.3845 Q 122.102 66.412, 120.799 67.5705 Q 119.516 68.7084, 117.075 68.7084 L 112.151 68.7084 L 112.151 54.061 L 116.475 54.061 Q 118.978 54.061, 120.24 55.0747 Q 121.502 56.0885, 121.502 57.9504 Q 121.502 60.1641, 119.268 61.0123 M 114.116 55.7161 L 114.116 60.3089 L 116.475 60.3089 Q 117.923 60.3089, 118.668 59.7296 Q 119.433 59.1297, 119.433 57.9504 Q 119.433 55.7161, 116.475 55.7161 L 114.116 55.7161 M 117.075 67.0533 Q 118.502 67.0533, 119.268 66.3706 Q 120.033 65.6879, 120.033 64.3845 Q 120.033 63.1846, 119.185 62.5846 Q 118.358 61.964, 116.765 61.964 L 114.116 61.964 L 114.116 67.0533 L 117.075 67.0533 \" fill=\"#7F4C19\"/>\n<path class=\"atom-21\" d=\"M 125.433 58.0746 L 125.661 59.5434 Q 126.778 57.8884, 128.598 57.8884 Q 129.178 57.8884, 129.964 58.0952 L 129.653 59.8331 Q 128.764 59.6262, 128.267 59.6262 Q 127.398 59.6262, 126.819 59.9779 Q 126.261 60.3089, 125.805 61.1158 L 125.805 68.7084 L 123.861 68.7084 L 123.861 58.0746 L 125.433 58.0746 \" fill=\"#7F4C19\"/>\n<path class=\"atom-26\" d=\"M 217.945 61.0123 Q 219.351 61.4054, 220.055 62.2743 Q 220.779 63.1225, 220.779 64.3845 Q 220.779 66.412, 219.476 67.5705 Q 218.193 68.7084, 215.752 68.7084 L 210.828 68.7084 L 210.828 54.061 L 215.152 54.061 Q 217.655 54.061, 218.917 55.0747 Q 220.179 56.0885, 220.179 57.9504 Q 220.179 60.1641, 217.945 61.0123 M 212.793 55.7161 L 212.793 60.3089 L 215.152 60.3089 Q 216.6 60.3089, 217.345 59.7296 Q 218.11 59.1297, 218.11 57.9504 Q 218.11 55.7161, 215.152 55.7161 L 212.793 55.7161 M 215.752 67.0533 Q 217.179 67.0533, 217.945 66.3706 Q 218.71 65.6879, 218.71 64.3845 Q 218.71 63.1846, 217.862 62.5846 Q 217.034 61.964, 215.441 61.964 L 212.793 61.964 L 212.793 67.0533 L 215.752 67.0533 \" fill=\"#7F4C19\"/>\n<path class=\"atom-26\" d=\"M 224.11 58.0746 L 224.337 59.5434 Q 225.455 57.8884, 227.275 57.8884 Q 227.854 57.8884, 228.641 58.0952 L 228.33 59.8331 Q 227.441 59.6262, 226.944 59.6262 Q 226.075 59.6262, 225.496 59.9779 Q 224.937 60.3089, 224.482 61.1158 L 224.482 68.7084 L 222.537 68.7084 L 222.537 58.0746 L 224.11 58.0746 \" fill=\"#7F4C19\"/>\n<path class=\"atom-27\" d=\"M 258.542 89.9726 Q 258.542 86.4556, 260.28 84.4902 Q 262.018 82.5248, 265.266 82.5248 Q 268.514 82.5248, 270.252 84.4902 Q 271.99 86.4556, 271.99 89.9726 Q 271.99 93.531, 270.231 95.5585 Q 268.473 97.5653, 265.266 97.5653 Q 262.038 97.5653, 260.28 95.5585 Q 258.542 93.5517, 258.542 89.9726 M 265.266 95.9102 Q 267.5 95.9102, 268.7 94.4206 Q 269.921 92.9104, 269.921 89.9726 Q 269.921 87.0969, 268.7 85.6487 Q 267.5 84.1799, 265.266 84.1799 Q 263.032 84.1799, 261.811 85.6281 Q 260.611 87.0762, 260.611 89.9726 Q 260.611 92.9311, 261.811 94.4206 Q 263.032 95.9102, 265.266 95.9102 \" fill=\"#FF0000\"/>\n<path class=\"atom-28\" d=\"M 267.407 146.4 Q 268.814 146.793, 269.517 147.662 Q 270.241 148.51, 270.241 149.772 Q 270.241 151.8, 268.938 152.958 Q 267.655 154.096, 265.214 154.096 L 260.29 154.096 L 260.29 139.449 L 264.614 139.449 Q 267.117 139.449, 268.379 140.463 Q 269.641 141.476, 269.641 143.338 Q 269.641 145.552, 267.407 146.4 M 262.256 141.104 L 262.256 145.697 L 264.614 145.697 Q 266.062 145.697, 266.807 145.118 Q 267.573 144.518, 267.573 143.338 Q 267.573 141.104, 264.614 141.104 L 262.256 141.104 M 265.214 152.441 Q 266.642 152.441, 267.407 151.759 Q 268.173 151.076, 268.173 149.772 Q 268.173 148.573, 267.324 147.973 Q 266.497 147.352, 264.904 147.352 L 262.256 147.352 L 262.256 152.441 L 265.214 152.441 \" fill=\"#7F4C19\"/>\n<path class=\"atom-28\" d=\"M 273.572 143.462 L 273.8 144.931 Q 274.917 143.276, 276.738 143.276 Q 277.317 143.276, 278.103 143.483 L 277.793 145.221 Q 276.903 145.014, 276.407 145.014 Q 275.538 145.014, 274.958 145.366 Q 274.4 145.697, 273.945 146.504 L 273.945 154.096 L 272 154.096 L 272 143.462 L 273.572 143.462 \" fill=\"#7F4C19\"/>\n<path class=\"atom-29\" d=\"M 260.304 198.752 L 265.104 206.51 Q 265.58 207.276, 266.345 208.662 Q 267.111 210.048, 267.152 210.131 L 267.152 198.752 L 269.097 198.752 L 269.097 213.4 L 267.09 213.4 L 261.939 204.917 Q 261.339 203.924, 260.697 202.786 Q 260.077 201.649, 259.89 201.297 L 259.89 213.4 L 257.987 213.4 L 257.987 198.752 L 260.304 198.752 \" fill=\"#000000\"/>\n<path class=\"atom-29\" d=\"M 270.007 210.524 Q 270.007 208.827, 271.372 207.896 Q 272.738 206.966, 275.241 206.966 L 276.813 206.966 L 276.813 206.552 Q 276.813 205.228, 276.255 204.669 Q 275.717 204.111, 274.393 204.111 Q 273.545 204.111, 272.883 204.276 Q 272.221 204.421, 271.186 204.876 L 270.607 203.531 Q 272.552 202.58, 274.434 202.58 Q 276.689 202.58, 277.724 203.552 Q 278.758 204.504, 278.758 206.593 L 278.758 213.4 L 277.248 213.4 Q 277.227 213.317, 277.165 213.007 Q 277.103 212.675, 276.979 212.158 Q 275.489 213.648, 273.503 213.648 Q 271.91 213.648, 270.959 212.8 Q 270.007 211.951, 270.007 210.524 M 271.952 210.483 Q 271.952 211.269, 272.448 211.703 Q 272.945 212.117, 273.876 212.117 Q 274.703 212.117, 275.489 211.745 Q 276.276 211.351, 276.813 210.689 L 276.813 208.414 L 275.365 208.414 Q 273.669 208.414, 272.8 208.931 Q 271.952 209.448, 271.952 210.483 \" fill=\"#000000\"/>\n<path class=\"atom-29\" d=\"M 279.987 203.182 L 282.568 203.182 L 282.568 200.465 L 283.715 200.465 L 283.715 203.182 L 286.364 203.182 L 286.364 204.165 L 283.715 204.165 L 283.715 206.896 L 282.568 206.896 L 282.568 204.165 L 279.987 204.165 L 279.987 203.182 \" fill=\"#000000\"/>\n<path class=\"atom-30\" d=\"M 15.9535 80.6387 L 20.7532 88.3969 Q 21.229 89.1623, 21.9945 90.5484 Q 22.7599 91.9346, 22.8013 92.0173 L 22.8013 80.6387 L 24.746 80.6387 L 24.746 95.2861 L 22.7393 95.2861 L 17.5878 86.8038 Q 16.9879 85.8108, 16.3465 84.6729 Q 15.7259 83.5351, 15.5397 83.1834 L 15.5397 95.2861 L 13.6364 95.2861 L 13.6364 80.6387 L 15.9535 80.6387 \" fill=\"#000000\"/>\n<path class=\"atom-30\" d=\"M 25.6563 92.4104 Q 25.6563 90.714, 27.0218 89.783 Q 28.3872 88.852, 30.8905 88.852 L 32.4628 88.852 L 32.4628 88.4382 Q 32.4628 87.1142, 31.9042 86.5556 Q 31.3663 85.997, 30.0423 85.997 Q 29.194 85.997, 28.532 86.1625 Q 27.87 86.3073, 26.8356 86.7625 L 26.2563 85.4177 Q 28.201 84.4661, 30.0836 84.4661 Q 32.3387 84.4661, 33.3731 85.4384 Q 34.4075 86.3901, 34.4075 88.4796 L 34.4075 95.2861 L 32.8973 95.2861 Q 32.8766 95.2033, 32.8145 94.893 Q 32.7524 94.562, 32.6283 94.0448 Q 31.1387 95.5343, 29.1527 95.5343 Q 27.5597 95.5343, 26.608 94.6861 Q 25.6563 93.8379, 25.6563 92.4104 M 27.601 92.369 Q 27.601 93.1552, 28.0976 93.5896 Q 28.5941 94.0034, 29.5251 94.0034 Q 30.3526 94.0034, 31.1387 93.631 Q 31.9249 93.2379, 32.4628 92.5759 L 32.4628 90.3002 L 31.0146 90.3002 Q 29.3182 90.3002, 28.4493 90.8174 Q 27.601 91.3346, 27.601 92.369 \" fill=\"#000000\"/>\n<path class=\"atom-30\" d=\"M 35.6364 85.0685 L 38.2171 85.0685 L 38.2171 82.3513 L 39.364 82.3513 L 39.364 85.0685 L 42.013 85.0685 L 42.013 86.0516 L 39.364 86.0516 L 39.364 88.7825 L 38.2171 88.7825 L 38.2171 86.0516 L 35.6364 86.0516 L 35.6364 85.0685 \" fill=\"#000000\"/>\n</svg>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLpEeS5pM9cW",
        "outputId": "d4dae75e-c245-452e-b417-199a10551625"
      },
      "source": [
        "train_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Formula', 'FW', 'DSSTox_CID', 'SR-HSE', 'NR-AR', 'SR-ARE',\n",
              "       'NR-Aromatase', 'NR-ER-LBD', 'NR-AhR', 'SR-MMP', 'NR-ER',\n",
              "       'NR-PPAR-gamma', 'SR-p53', 'SR-ATAD5', 'NR-AR-LBD'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Js0JxpZ_M-_S",
        "outputId": "4515059d-ff8d-45cc-f9f3-401cdcb0f997"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "hoge = train_df.iloc[0:20,3:15].to_numpy()\n",
        "dumb = plt.imshow(hoge*255,extent=[0,12,0,20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "w6BRzem8NRVt",
        "outputId": "9f66529e-4287-40b2-cc3b-6de0af016ad6"
      },
      "source": [
        "plt.plot(train_df['SR-MMP'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9b5b4b5590>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO4ErnvqNTKs",
        "outputId": "580fa1b3-22f7-4c41-c4ed-22a80a78125c"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, Dropout, Activation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y0trsWhNUnL"
      },
      "source": [
        "from rdkit.Chem import AllChem\n",
        "n0 = 1000\n",
        "n_train = 8000\n",
        "n_test = 2000\n",
        "\n",
        "tmp = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, 1024) for mol in train_x[n0:(n0+n_train)]]\n",
        "x_train = np.stack(tmp,0)\n",
        "y_train = train_df['SR-MMP'][n0:(n0+n_train)]\n",
        "y_train[np.isnan(y_train)] = 0.5\n",
        "\n",
        "tmp = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, 1024) for mol in train_x[(n0+n_train):(n0+n_train+n_test)]]\n",
        "x_test = np.stack(tmp,0)\n",
        "y_test = train_df['SR-MMP'][(n0+n_train):(n0+n_train+n_test)]\n",
        "y_test[np.isnan(y_test)] = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amVtbGmRNZVG",
        "outputId": "db5a035d-6295-4a3a-9fe7-0d624c33cc9f"
      },
      "source": [
        "print(np.mean(y_train))\n",
        "print(np.mean(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.343625\n",
            "0.05175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWKFrXVDNax5",
        "outputId": "63e49ec8-14ac-41bc-eacb-50d9a4e17157"
      },
      "source": [
        "model1 = Sequential()\n",
        "#model1.add(Dense(16, input_shape=(1024,), activation='relu'))\n",
        "#model1.add(Dropout(0.5))\n",
        "#model1.add(Dense(16, activation='softmax'))\n",
        "#model1.add(Dense(16, activation='softmax'))\n",
        "#model1.add(Dense(1, activation='softmax'))\n",
        "#model1.summary()\n",
        "\n",
        "model1.add(Dense(16, input_shape=(1024,),activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(16, activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(1, activation='softmax'))\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "dense_31 (Dense)                 (None, 16)            16400       dense_input_9[0][0]              \n",
            "____________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)             (None, 16)            0           dense_31[0][0]                   \n",
            "____________________________________________________________________________________________________\n",
            "dense_32 (Dense)                 (None, 16)            272         dropout_13[0][0]                 \n",
            "____________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)             (None, 16)            0           dense_32[0][0]                   \n",
            "____________________________________________________________________________________________________\n",
            "dense_33 (Dense)                 (None, 1)             17          dropout_14[0][0]                 \n",
            "====================================================================================================\n",
            "Total params: 16,689\n",
            "Trainable params: 16,689\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_7YlAnLGxhz"
      },
      "source": [
        "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPnxRtfJG8yA",
        "outputId": "afbe0efc-a1ce-493a-e10c-f00115d9f47d"
      },
      "source": [
        "#reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,patience=50, min_lr=0.00001, verbose=1)\n",
        "#Training\n",
        "#history = model1.fit(x_train, y_train, nb_epoch=200, batch_size=500, validation_data=(x_test,y_test), callbacks=[reduce_lr])\n",
        "model1.fit(x_train, y_train,\n",
        "          nb_epoch=100,\n",
        "          batch_size=500,\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1282     \n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 0s - loss: 10.4642 - acc: 0.1283     \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b4a90a350>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "OTsEChfzHxbf",
        "outputId": "c859714e-4213-40cc-ed87-013e2e45b49b"
      },
      "source": [
        "def plot_history(history):\n",
        "    lw = 2\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.plot(history.epoch, history.history['binary_crossentropy'],c='b', label=\"Train\", lw=lw)\n",
        "    ax1.plot(history.epoch, history.history['val_loss'],c='g', label=\"Val\", lw=lw)\n",
        "    plt.ylim([0.0, max(history.history['binary_crossentropy'])])\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(history.epoch, history.history['lr'],c='r', label=\"Learning Rate\", lw=lw)\n",
        "    ax2.set_ylabel('Learning rate')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIE_Lu6NIX3p",
        "outputId": "90fb7f81-4051-4ac3-dfd9-b1a3471c7c6e"
      },
      "source": [
        "y_pred = model1.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqRvmXRSoeo_",
        "outputId": "0b44b545-8966-432a-83e8-408c97ffdf6c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000    0.5\n",
              "1001    0.5\n",
              "1002    0.5\n",
              "1003    0.5\n",
              "1004    0.5\n",
              "       ... \n",
              "8995    0.0\n",
              "8996    0.5\n",
              "8997    0.0\n",
              "8998    0.5\n",
              "8999    0.5\n",
              "Name: SR-MMP, Length: 8000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vn2ja2JqdmY",
        "outputId": "cf4887c4-94cd-4d1b-b138-680c5f3679f3"
      },
      "source": [
        "print(y_train.unique())\n",
        "print(y_test.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5 1.  0. ]\n",
            "[0.  0.5 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpD5l1p9sT4d",
        "outputId": "52ac3cc4-eaa5-4596-f88d-fcac351c4f75"
      },
      "source": [
        "np.unique(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "7fMPkvs3H0jw",
        "outputId": "fef15c30-c64e-4ba8-f8f9-8045e7ccafd4"
      },
      "source": [
        "def show_auc(model):\n",
        "    pred_train = model.predict(x_train)\n",
        "    #pred_train = pd.DataFrame(pred_train)\n",
        "    # pred_val = model.predict(x_val)\n",
        "    pred_test = model.predict(x_test)\n",
        "    #pred_test = pd.DataFrame(pred_test)\n",
        "    auc_train = roc_auc_score(y_train, pred_train)\n",
        "    # auc_val = roc_auc_score(y_val, pred_val)\n",
        "    auc_test = roc_auc_score(y_test, pred_test)\n",
        "    print(\"AUC, Train:%0.3F Test:%0.3F Val:%0.3F\"%(auc_train, auc_test, auc_val))\n",
        "    fpr_train, tpr_train, _ =roc_curve(y_train, pred_train)\n",
        "    fpr_val, tpr_val, _ = roc_curve(y_val, pred_val)\n",
        "    fpr_test, tpr_test, _ = roc_curve(y_test, pred_test)\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr_train, tpr_train, color='b',lw=lw, label='Train ROC (area = %0.2f)'%auc_train)\n",
        "    plt.plot(fpr_val, tpr_val, color='g',lw=lw, label='Val ROC (area = %0.2f)'%auc_val)\n",
        "    plt.plot(fpr_test, tpr_test, color='r',lw=lw, label='Test ROC (area = %0.2f)'%auc_test)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic of %s'%prop)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.interactive(True)\n",
        "    plt.show()\n",
        "show_auc(model1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-f8428b085640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mshow_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-94-f8428b085640>\u001b[0m in \u001b[0;36mshow_auc\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#pred_test = pd.DataFrame(pred_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mauc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# auc_val = roc_auc_score(y_val, pred_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mauc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         )\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: continuous format is not supported"
          ]
        }
      ]
    }
  ]
}